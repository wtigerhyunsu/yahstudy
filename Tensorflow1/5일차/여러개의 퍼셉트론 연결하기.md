## 여러개의 퍼셉트론 연결하기 

![image-20200820091047369](https://user-images.githubusercontent.com/58680521/90704508-a56f6180-e2cb-11ea-878e-abd830fd6fe4.PNG)

> hidden layer 와 ouput layer 부분만 짤라서 보면 5개의 입력를 받고 1출력을 만드는 모델이라고 생각할수있다 
>
> input layer 와 hidden layer 부분만 짤라서 보면13개의 입력을 받고 5개 의 출력을 만드는 모델이라고 할수있습니다
>
> 각각의 모델을 연속적으로 연결하여 하나의 거대한 신경망을 만드는 것을 **Deep learning 인공신경망**입니다 

```python
X = tf.keras.layer.Input(shape=[13])
#hidden layer를 추가하는 코드
H = tf.keras.layer.Dense(5, activation='swish')(X)#활성화 함수로는 swish(스위시)를 사용 했다 # 최근에 발표된 성능이 좋은 활성화함수 이다 
H = tf.keras.layer.Dense(3, activation='swish')(H)
H = tf.keras.layer.Dense(3, activation='swish')(H)
Y = tf.keras.layer.Dense(1)(H)#마지막 출력을 만들떄 H를 넣어 줘야 된다 
model = tf.keras.models.Model(X,Y)
model.compile(loss='mse')
```

![image-20200820093349204](https://user-images.githubusercontent.com/58680521/90704542-bb7d2200-e2cb-11ea-8eda-cb9e834b64f9.png)

### model.summary()

> 코드 해석  : 13개의 입력을 받아서 2번째 층은 13개의 입력을 받고 10개의 ouput 을 만들고 마지막 출력층은 10개의 입력을 받아서 1개의 출력을 한다 param 가중치의 갯수 이다  13의 가중치에 bias 1개의 항이 추가 되서 14 * 10 하면 140 개의 가충치가 나오고 10의 가중치에서 bias 1개의 항이 추가 되서 11 * 1 열한개 의 가중치가 나온다 
>
> 